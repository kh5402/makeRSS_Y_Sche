import os
import re
from bs4 import BeautifulSoup
from pyppeteer import launch
from xml.etree.ElementTree import Element, SubElement, tostring, ElementTree
from datetime import datetime, timedelta
import xml.dom.minidom
import xml.etree.ElementTree as ET
import asyncio
import requests

# æ—¢å­˜ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æƒ…å ±å–å¾—
def get_existing_schedules(file_name):
    existing_schedules = set()
    tree = ET.parse(file_name)
    root = tree.getroot()
    for item in root.findall(".//item"):
        date = item.find('pubDate').text
        title = item.find('title').text
        url = item.find('link').text
        category = item.find('category').text
        start_time = item.find('start_time').text
        existing_schedules.add((date, title, url, category, start_time))
    return existing_schedules



async def main():

    # Discordã®webhook URLã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    webhook_url = os.environ['WEBHOOK_URL']

    # æ—¢å­˜ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°ã€ãã®æƒ…å ±ã‚’å–å¾—
    existing_file = 'Y_Sche.xml'
    existing_schedules = get_existing_schedules(existing_file) if os.path.exists(existing_file) else set()

    # å¾Œã§é‡è¤‡ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ãã®ç‚ºã®ä¸€è¦§
    existing_schedules_check = {(date, title) for date, title, _, _, _ in existing_schedules}
    
    # æ–°è¦æƒ…å ±ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
    new_schedules = []

    # å…ˆæœˆã®1æ—¥ã‹ã‚‰3ãƒ¶æœˆå…ˆã¾ã§ã®yyyymmã‚’ç”Ÿæˆ
    start_date = (datetime.today().replace(day=1) - timedelta(days=1)).replace(day=1)
    end_date = start_date + timedelta(days=90)
    current_date = start_date
    schedules = []
    while current_date <= end_date:
        
        yyyymm = current_date.strftime('%Y%m')
        url = f"https://www.nogizaka46.com/s/n46/media/list?dy={yyyymm}&members={{%22member%22:[%2255387%22]}}"
        print('yyyymmï¼š' + yyyymm + ' urlï¼š' + url)

        
        # Pyppeteerã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ã
        browser = await launch(
            executablePath='/usr/bin/chromium-browser',
            headless=True,
            args=[
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--disable-accelerated-2d-canvas',
                '--disable-gpu'
            ],
        )
        
        page = await browser.newPage()
        await page.setExtraHTTPHeaders({'Accept-Language': 'ja'})
        await page.goto(url)

        # ãƒ­ã‚°å‡ºåŠ›ã‚’è¿½åŠ 
        print("ç¾åœ¨ã®HTTPãƒ˜ãƒƒãƒ€ãƒ¼:", await page.headers())

        # ãƒšãƒ¼ã‚¸ã®HTMLã‚’å–å¾—
        html = await page.content()
        
        # BeautifulSoupã§è§£æ
        soup = BeautifulSoup(html, 'html.parser')

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã®å–å¾—
        day_schedules = soup.find_all('div', class_='sc--day')

        # å„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æƒ…å ±ã‚’å–å¾—
        for day_schedule in day_schedules:
            date_tag = day_schedule.find('div', class_='sc--day__hd js-pos a--tx')
            if date_tag is None:
                continue
            date = f"{yyyymm[:4]}/{yyyymm[4:]}/{date_tag.find('p', class_='sc--day__d f--head').text}"
            
            schedule_links = day_schedule.find_all('a', class_='m--scone__a hv--op')
            
            for link in schedule_links:
                
                title = re.search(r'<p class="m--scone__ttl">(.*?)</p>', str(link.find('p', class_='m--scone__ttl'))).group(1)
                title_tag = link.find('p', class_='m--scone__ttl')
                if title_tag:
                    title = title_tag.get_text()
                    
                url = link['href']
                category = link.find('p', class_='m--scone__cat__name').text
                start_time_tag = link.find('p', class_='m--scone__start')
                start_time = start_time_tag.text if start_time_tag else ''

                
                # æ–°è¦æƒ…å ±ã®ç¢ºèª URLã¯å¤‰ã‚ã‚‹ã®ã§æ—¥ä»˜ã¨ã‚¿ã‚¤ãƒˆãƒ«ã ã‘ã§ç¢ºèª
                if (date, title) not in existing_schedules_check: 
                    new_schedules.append((date, title, url, category, start_time))
                
        # æ¬¡ã®æœˆã¸        
        current_date = (current_date + timedelta(days=31)).replace(day=1)
        if current_date.day != 1: # æœˆã®æœ€åˆã®æ—¥ã§ã¯ãªã„å ´åˆ
            current_date = (current_date + timedelta(days=1)).replace(day=1) # æœˆã‚’1ã¤é€²ã‚ã‚‹
    
    # æ–°è¦æƒ…å ±ãŒã‚ã‚Œã°ã€Discordã¸é€šçŸ¥
    print('# æ–°è¦æƒ…å ±ãŒã‚ã‚Œã°ã€Discordã¸é€šçŸ¥')
    print(new_schedules)
    for date, title, url, category, start_time in new_schedules:
        discord_message = f"æ–°ã—ã„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚„ã§ï¼ğŸ‰ğŸ’–\næ—¥ä»˜: {date}\né–‹å§‹æ™‚é–“: {start_time}\nã‚«ãƒ†ã‚´ãƒª: {category}\nã‚¿ã‚¤ãƒˆãƒ«: {title}\nURL: {url}\n"
        payload = {"content": discord_message}
        await asyncio.sleep(1)

        # Discordã¸ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
        response = requests.post(webhook_url, json=payload)
        if response.status_code != 204:
            print(f"é€šçŸ¥ã«å¤±æ•—ã—ãŸã§: {response.text}") # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            
    # æ—¢å­˜ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚‚ãƒªã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
    existing_schedules_list = [(date, title, url, category, start_time) for date, title, url, category, start_time in existing_schedules]
    
    # æ—¢å­˜ã®æƒ…å ±ã¨æ–°è¦æƒ…å ±ã‚’åˆã‚ã›ã‚‹
    all_schedules = existing_schedules_list + new_schedules

    # æ—¥ä»˜ã®é™é †ã«ã‚½ãƒ¼ãƒˆ
    all_schedules.sort(key=lambda x: datetime.strptime(x[0], "%Y/%m/%d"), reverse=True)

    # RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
    rss = Element("rss", version="2.0")
    channel = SubElement(rss, "channel")
    SubElement(channel, "title").text = "å¼“æœ¨å¥ˆæ–¼ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"
    SubElement(channel, "description").text = ""
    SubElement(channel, "link").text = ""
    for date, title, url, category, start_time in all_schedules:
        item = SubElement(channel, "item")
        SubElement(item, "title").text = title
        SubElement(item, "link").text = url
        SubElement(item, "pubDate").text = date
        SubElement(item, "category").text = category
        SubElement(item, "start_time").text = start_time

    
    xml_str = xml.dom.minidom.parseString(tostring(rss)).toprettyxml(indent="   ")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(existing_file, 'w', encoding='utf-8') as f:
        f.write(xml_str)

# éåŒæœŸé–¢æ•°ã‚’å®Ÿè¡Œ
asyncio.get_event_loop().run_until_complete(main())
